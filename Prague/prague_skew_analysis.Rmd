---
title: "pwr_analysis_final_fix.rmd"
author: "Nikolas McNeal"
date: "10/31/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#packageurl<-"https://cran.r-project.org/src/contrib/Archive/nloptr/nloptr_1.2.1.tar.gz"
#install.packages(packageurl, repos=NULL, type="source")

install.packages('simr')
```


```{r}
library(plyr)
library(tidyverse)
library(lme4)
library(lmerTest)
library(simr)


new.df = read.csv("/Users/nikolasmcneal/RStudio Workspace/Color_Discrimination/Prague/Prague_exp_data_skew.csv")
```


```{r}
new.df
```


```{r}

# run LV, MV, HV



new.df <- new.df %>% 
  group_by(SubjectNumber) %>% 
  mutate(ValDif = abs(ValL - ValR),
         valGroup = ifelse(
           OV < quantile(OV, probs = .25), "LV",
           ifelse(OV > quantile(OV, probs = .75), "HV",
           "MV"
          ))
         ) %>%
  ungroup()



model.LV = glmer(data = new.df[new.df$valGroup == "LV", ],
              formula = accuracy ~ ValDif + skew*I(valSum/100) + (1|cond:subject) + (0+ValDif|cond:subject) + (0+skew|cond:subject) + (0+I(valSum/100)|cond:subject), 
              family = binomial(link="logit"),
              control = glmerControl(optimizer = "bobyqa")
              )

model.MV = glmer(data = new.df[new.df$valGroup == "MV", ],
              formula = accuracy ~ ValDif + skew*I(valSum/100) + (1|cond:subject) + (0+ValDif|cond:subject) + (0+skew|cond:subject) + (0+I(valSum/100)|cond:subject), 
              family = binomial(link="logit"),
              control = glmerControl(optimizer = "bobyqa")
              )


model.HV = glmer(data = new.df[new.df$valGroup == "HV", ],
              formula = accuracy ~ ValDif + skew*I(valSum/100) + (1|cond:subject) + (0+ValDif|cond:subject) + (0+skew|cond:subject) + (0+I(valSum/100)|cond:subject), 
              family = binomial(link="logit"),
              control = glmerControl(optimizer = "bobyqa")
              )

model.full_1 = glmer(data = new.df,
              formula = accuracy ~ ValDif + skew*I(valSum/100) + (1|cond:subject) + (0+ValDif|cond:subject) + (0+skew|cond:subject) + (0+I(valSum/100)|cond:subject), 
              family = binomial(link="logit"),
              control = glmerControl(optimizer = "bobyqa")
              )

model.full_2 = glmer(data = new.df,
              formula = accuracy ~ ValDif + skew*(valGroup) + (1|cond:subject) + (0+ValDif|cond:subject) + (0+skew|cond:subject) + (0+(valGroup)|cond:subject), 
              family = binomial(link="logit"),
              control = glmerControl(optimizer = "bobyqa")
              )


```

```{r}
library(ggpubr)

new.df %>% 
  group_by(SubjectNumber, valGroup, ValDif) %>%
  mutate(acc = mean(accuracy)) %>%
  group_by(SubjectNumber, valGroup) %>%
  mutate(m_acc = mean(acc)) %>%
  ungroup() %>%
  ggplot(aes(x=skew, y=m_acc, color=valGroup)) + 
  theme_pubr() +
  geom_smooth(method = 'lm') +
  ggtitle('Prague_Data')

```


```{r}
data$valSum <- ((data$Left_sum + data$Right_sum)/100)
data$choice <- data$accuracy
data$nValD = abs(data$X.L.R.)
data$ValDif = data$absRelativeValue
data$SubjectNumber = data$subj_idx
data$cond <- factor(data$task, levels = c("experiment_FR","experiment_VB"),
                   labels = c("Fixed Reward","Value Reward"))

model <- glmer(data=data,
                        formula = choice ~ nValD + ValDif + valSum*cond +  (1|SubjectNumber) + (0+nValD|SubjectNumber) +(0+cond|SubjectNumber)+ (0+ValDif|SubjectNumber) + (0+valSum|SubjectNumber),
                        family = binomial(link="logit"),
                        control = glmerControl(optimizer = "bobyqa")
)
summary(model)






sim.model_new = extend(model, along="SubjectNumber", n=200)

pcurve_new <- powerCurve(sim.model_new,
                        nsim=1,
                        fixed("valSum:condValue Reward", "z"),  # changed to reflect new variable name with dummy coding
                        alpha = .045,
                        along = "SubjectNumber",
                        breaks=seq(80, 100, 10) # <- use low value from earlier exercise here
)
pcurve_new


obs_VB.model <- glmer(data=data[data$task == "experiment_VB", ],
                   formula = accuracy ~ nValD + ValDif + valSum +
                     (1|SubjectNumber) + (0 + nValD|SubjectNumber) + (0+ValDif|SubjectNumber) + (0 + valSum|SubjectNumber),
                   family = binomial(link="logit"),
                   control = glmerControl(optimizer = "bobyqa"))

obs_FR.model <- glmer(data=data[data$task == "experiment_FR", ],
                   formula = accuracy ~ nValD + ValDif + valSum +
                     (1|SubjectNumber) + (0 + nValD|SubjectNumber) + (0+ValDif|SubjectNumber) + (0 + valSum|SubjectNumber),
                   family = binomial(link="logit"),
                   control = glmerControl(optimizer = "bobyqa"))

nSubj <- length(unique(data$SubjectNumber)) #52


#Increase effect size to the upper end of the 50% CI
#effSize_VB = confint(obs_VB.model,"valSum",level = .5, method="Wald")[2]

#Reduce effect size to the lower end of the 80% CI
effSize_FR = confint(obs_FR.model,"valSum",level = .8, method="Wald")[1]


sim.model_1 <- obs_VB.model
sim.model_0 <- obs_FR.model

#sim model 1 is VB , sim model 2 is acc based
#fixef(sim.model_1)["valSum"] <- effSize_VB
fixef(sim.model_0)["valSum"] <- effSize_FR

n = 200 #max sample size

sim.model_1_ext <- extend(sim.model_1, along="SubjectNumber", n=n)
sim.model_0_ext <- extend(sim.model_0, along="SubjectNumber", n=n)
sim_1.data = getData(sim.model_1_ext)
sim_1.data$choice <- doSim(sim.model_1_ext)
sim_1.data$cond = 1
sim_0.data = getData(sim.model_0_ext)
sim_0.data$choice <- doSim(sim.model_0_ext)
sim_0.data$cond = 0

sim.model_0<- glmer(data=sim_0.data,
                        formula = choice ~ nValD + ValDif + valSum+  (1|SubjectNumber) + (0+nValD|SubjectNumber) + (0+ValDif|SubjectNumber) + (0+valSum|SubjectNumber),
                        family = binomial(link="logit"),
                        control = glmerControl(optimizer = "bobyqa")
)
summary(sim.model_0) # Make sure valSum isn't significant in this condition

sim.data <- rbind(sim_0.data,sim_1.data)
sim.data$cond <- factor(sim.data$cond, levels = c(0,1),
                   labels = c("Fixed Reward","Value Reward"))
#Generate new model where condition varies the effect
sim.model_new <- glmer(data=sim.data,
                        formula = choice ~ nValD + ValDif + valSum*cond +  (1|SubjectNumber) + (0+nValD|SubjectNumber) +(0+cond|SubjectNumber)+ (0+ValDif|SubjectNumber) + (0+valSum|SubjectNumber),
                        family = binomial(link="logit"),
                        control = glmerControl(optimizer = "bobyqa")
)
summary(sim.model_new)
# valueSum * cond should be significant here, because this is largest sample size

pcurve_new <- powerCurve(sim.model_new,
                        nsim=1,
                        fixed("valSum:cond", "z"),
                        alpha = .045,
                        along = "SubjectNumber",
                        breaks=seq(100, 200, 10)
)
pcurve_new 
plot(pcurve_new)
```